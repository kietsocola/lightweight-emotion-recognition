{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8911ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“š Import thÆ° viá»‡n\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as mobilenet_preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85666922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing happy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7215/7215 [00:25<00:00, 277.75it/s]\n",
      "Processing sad: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4830/4830 [00:15<00:00, 305.39it/s]\n",
      "Processing fear: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4097/4097 [00:10<00:00, 399.74it/s]\n",
      "Processing surprise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3171/3171 [00:06<00:00, 482.74it/s]\n",
      "Processing neutral: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4965/4965 [00:10<00:00, 486.58it/s]\n",
      "Processing angry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3995/3995 [00:08<00:00, 496.69it/s]\n",
      "Processing disgust: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436/436 [00:00<00:00, 457.90it/s]\n",
      "Processing happy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1774/1774 [00:03<00:00, 512.38it/s]\n",
      "Processing sad: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1247/1247 [00:02<00:00, 495.62it/s]\n",
      "Processing fear: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:01<00:00, 552.02it/s]\n",
      "Processing surprise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 831/831 [00:01<00:00, 438.82it/s]\n",
      "Processing neutral: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1233/1233 [00:02<00:00, 479.14it/s]\n",
      "Processing angry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 958/958 [00:02<00:00, 468.08it/s]\n",
      "Processing disgust: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<00:00, 566.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----- Cáº¥u hÃ¬nh -----\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "DATA_PATH = '../../../Bai_4/data'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')\n",
    "DARK_PATH = '../../../Bai_4/data_dark'\n",
    "ALGORITHM_PATH = '../../../Bai_4/data_algorithm'\n",
    "TRAIN_DARK_PATH = os.path.join(DARK_PATH, 'train')\n",
    "TEST_DARK_PATH = os.path.join(DARK_PATH, 'test')\n",
    "TRAIN_ALGORITHM_PATH = os.path.join(ALGORITHM_PATH, 'train')\n",
    "TEST_ALGORITHM_PATH = os.path.join(ALGORITHM_PATH, 'test')\n",
    "\n",
    "# Táº¡o cÃ¡c thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i\n",
    "os.makedirs(TRAIN_DARK_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_DARK_PATH, exist_ok=True)\n",
    "os.makedirs(TRAIN_ALGORITHM_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_ALGORITHM_PATH, exist_ok=True)\n",
    "\n",
    "# ----- HÃ m táº¡o áº£nh tá»‘i -----\n",
    "def create_dark_image(image, brightness_range=[0.1, 0.1]):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv[..., 2] = hsv[..., 2] * np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "# ----- HÃ m tÄƒng cÆ°á»ng sÃ¡ng -----\n",
    "def adaptive_augmentation(image, T1=50, T2=100, gamma_low=0.5, gamma_mid=0.8):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    mean_intensity = np.mean(gray)\n",
    "    if mean_intensity < T1:\n",
    "        image = gamma_correction(image, gamma_low)\n",
    "    elif T1 <= mean_intensity < T2:\n",
    "        image = gamma_correction(image, gamma_mid)\n",
    "    else:\n",
    "        image = contrast_stretching(image)\n",
    "    return image\n",
    "\n",
    "def gamma_correction(image, gamma):\n",
    "    table = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def contrast_stretching(image):\n",
    "    stretched = np.zeros_like(image)\n",
    "    for c in range(3):\n",
    "        min_val = np.min(image[:, :, c])\n",
    "        max_val = np.max(image[:, :, c])\n",
    "        stretched[:, :, c] = ((image[:, :, c] - min_val) * 255.0 / (max_val - min_val + 1e-6))\n",
    "    return stretched.astype(np.uint8)\n",
    "\n",
    "# ----- HÃ m xá»­ lÃ½ áº£nh -----\n",
    "def process_images_for_train_and_test(path, dark_path, algorithm_path):\n",
    "    for class_name in os.listdir(path):\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        # Táº¡o thÆ° má»¥c cho áº£nh tá»‘i vÃ  áº£nh sau thuáº­t toÃ¡n\n",
    "        dark_class_path = os.path.join(dark_path, class_name)\n",
    "        algorithm_class_path = os.path.join(algorithm_path, class_name)\n",
    "        \n",
    "        os.makedirs(dark_class_path, exist_ok=True)\n",
    "        os.makedirs(algorithm_class_path, exist_ok=True)\n",
    "\n",
    "        for file_name in tqdm(os.listdir(class_path), desc=f\"Processing {class_name}\"):\n",
    "            input_file = os.path.join(class_path, file_name)\n",
    "            \n",
    "            # Äá»c áº£nh, resize vÃ  chuyá»ƒn sang RGB\n",
    "            img = cv2.imread(input_file)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 1. Táº¡o áº£nh tá»‘i vÃ  lÆ°u\n",
    "            dark_img = create_dark_image(img_rgb)\n",
    "            dark_file_path = os.path.join(dark_class_path, file_name)\n",
    "            cv2.imwrite(dark_file_path, cv2.cvtColor(dark_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # 2. Ãp dá»¥ng thuáº­t toÃ¡n tÄƒng cÆ°á»ng sÃ¡ng vÃ  lÆ°u áº£nh\n",
    "            enhanced_img = adaptive_augmentation(dark_img)\n",
    "            enhanced_file_path = os.path.join(algorithm_class_path, file_name)\n",
    "            cv2.imwrite(enhanced_file_path, cv2.cvtColor(enhanced_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Gá»i hÃ m Ä‘á»ƒ xá»­ lÃ½ áº£nh trong táº­p train vÃ  test\n",
    "process_images_for_train_and_test(TRAIN_PATH, TRAIN_DARK_PATH, TRAIN_ALGORITHM_PATH)\n",
    "process_images_for_train_and_test(TEST_PATH, TEST_DARK_PATH, TEST_ALGORITHM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a78ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n",
      "Tá»•ng sá»‘ áº£nh train: 28709\n",
      "Tá»•ng sá»‘ áº£nh val: 3589\n",
      "Tá»•ng sá»‘ áº£nh test: 3589\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# DÃ¹ng ImageDataGenerator cho train\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=mobilenet_preprocess_input,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../../../Bai_4/data_algorithm/train',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load toÃ n bá»™ test áº£nh\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=mobilenet_preprocess_input,\n",
    ")\n",
    "\n",
    "full_test_generator = test_datagen.flow_from_directory(\n",
    "    '../../../Bai_4/data_algorithm/test',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Táº£i toÃ n bá»™ áº£nh test ra numpy array\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for i in range(len(full_test_generator)):\n",
    "    x, y = full_test_generator[i]\n",
    "    test_images.append(x[0])\n",
    "    test_labels.append(y[0])\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Chia Ä‘Ã´i test thÃ nh val vÃ  test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    test_images, test_labels, test_size=0.5, random_state=42, stratify=test_labels\n",
    ")\n",
    "\n",
    "# Táº¡o generator tá»« numpy\n",
    "val_generator = test_datagen.flow(\n",
    "    X_val, y_val, batch_size=1, shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    X_val, y_val, batch_size=1, shuffle=False\n",
    ")\n",
    "print(f\"Tá»•ng sá»‘ áº£nh train: {train_generator.n}\")\n",
    "print(f\"Tá»•ng sá»‘ áº£nh val: {val_generator.n}\")\n",
    "print(f\"Tá»•ng sá»‘ áº£nh test: {test_generator.n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
