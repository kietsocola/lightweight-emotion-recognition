{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829be710",
   "metadata": {},
   "source": [
    "## Chuong 25\n",
    "- XÃ¢y dá»±ng mÃ´ hÃ¬nh CNN Ä‘Æ¡n giáº£n\n",
    "- Chi tiáº¿t kiáº¿n trÃºc:\n",
    "Conv2D (32 filters, 5x5 kernel): Lá»›p tÃ­ch cháº­p trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh Ä‘áº§u vÃ o.\n",
    "MaxPooling2D(): Giáº£m kÃ­ch thÆ°á»›c áº£nh Ä‘áº·c trÆ°ng vÃ  tÄƒng tÃ­nh khÃ¡i quÃ¡t.\n",
    "Dropout(0.2): Giáº£m overfitting báº±ng cÃ¡ch vÃ´ hiá»‡u hÃ³a ngáº«u nhiÃªn 20% sá»‘ neuron trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.\n",
    "Flatten: Biáº¿n áº£nh Ä‘áº·c trÆ°ng 2D thÃ nh vector 1D.\n",
    "Dense(128, relu): Lá»›p fully-connected áº©n.\n",
    "Dense(10, softmax): Lá»›p Ä‘áº§u ra vá»›i 10 nhÃ£n tÆ°Æ¡ng á»©ng vá»›i 10 chá»¯ sá»‘ (0â€“9).\n",
    "\n",
    "ğŸ“š Dataset: MNIST (Modified National Institute of Standards and Technology)\n",
    "Gá»“m: 70.000 áº£nh grayscale 28x28 pixels cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« 0 Ä‘áº¿n 9.\n",
    "\n",
    "60.000 áº£nh huáº¥n luyá»‡n (training set)\n",
    "\n",
    "10.000 áº£nh kiá»ƒm tra (test set)\n",
    "\n",
    "Dá»¯ liá»‡u áº£nh: 1 kÃªnh (grayscale), kÃ­ch thÆ°á»›c 28x28.\n",
    "\n",
    "Dá»¯ liá»‡u nhÃ£n (label): CÃ¡c sá»‘ tá»« 0 Ä‘áº¿n 9.\n",
    "\n",
    "âœ… á»¨ng dá»¥ng thá»±c táº¿:\n",
    "BÃ i toÃ¡n phÃ¢n loáº¡i áº£nh Ä‘Æ¡n giáº£n.\n",
    "\n",
    "BÃ i há»c ná»n táº£ng vá» xá»­ lÃ½ áº£nh, nháº­n diá»‡n chá»¯ sá»‘, kiáº¿n trÃºc CNN.\n",
    "\n",
    "LÃ  bÃ i táº­p phá»• biáº¿n trong há»c mÃ¡y vÃ  deep learning nháº­p mÃ´n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ef14d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.8651 - loss: 0.4799 - val_accuracy: 0.9780 - val_loss: 0.0746\n",
      "Epoch 2/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9775 - loss: 0.0778 - val_accuracy: 0.9835 - val_loss: 0.0504\n",
      "Epoch 3/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9843 - loss: 0.0527 - val_accuracy: 0.9867 - val_loss: 0.0426\n",
      "Epoch 4/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9881 - loss: 0.0396 - val_accuracy: 0.9890 - val_loss: 0.0349\n",
      "Epoch 5/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9902 - loss: 0.0329 - val_accuracy: 0.9887 - val_loss: 0.0351\n",
      "Epoch 6/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9920 - loss: 0.0262 - val_accuracy: 0.9870 - val_loss: 0.0362\n",
      "Epoch 7/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9925 - loss: 0.0232 - val_accuracy: 0.9902 - val_loss: 0.0292\n",
      "Epoch 8/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9938 - loss: 0.0192 - val_accuracy: 0.9898 - val_loss: 0.0325\n",
      "Epoch 9/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9950 - loss: 0.0153 - val_accuracy: 0.9904 - val_loss: 0.0309\n",
      "Epoch 10/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9958 - loss: 0.0138 - val_accuracy: 0.9907 - val_loss: 0.0306\n",
      "CNN Error: 0.93%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN for the MNIST Dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one-hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe06fa9",
   "metadata": {},
   "source": [
    "ğŸ“Š Káº¿t quáº£ huáº¥n luyá»‡n mÃ´ hÃ¬nh CNN\n",
    "âš™ï¸ ThÃ´ng sá»‘ huáº¥n luyá»‡n:\n",
    "Sá»‘ epoch: 10\n",
    "Batch size: 200\n",
    "HÃ m máº¥t mÃ¡t: Categorical Crossentropy\n",
    "Bá»™ tá»‘i Æ°u hÃ³a: Adam\n",
    "\n",
    "âš™ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh:\n",
    "Conv2D(32 filters, 5x5) + ReLU\n",
    "MaxPooling2D()\n",
    "Dropout(0.2)\n",
    "Flatten\n",
    "Dense(128) + ReLU\n",
    "Dense(10) + Softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
