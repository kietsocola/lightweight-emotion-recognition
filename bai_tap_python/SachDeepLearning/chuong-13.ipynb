{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262e2a73",
   "metadata": {},
   "source": [
    "# Use Keras Deep Learning Models with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a4d19",
   "metadata": {},
   "source": [
    "## 13.2 Evaluate Deep Learning Models with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1165e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c992a3a",
   "metadata": {},
   "source": [
    "## 13.3 Grid Search Deep Learning Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2a13fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'class_weight'])\n",
      "Best: 0.696630 using {'batch_size': 20, 'epochs': 50, 'model__init': 'normal', 'optimizer': 'adam'}\n",
      "0.686156 (0.022171) with: {'batch_size': 10, 'epochs': 50, 'model__init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.696613 (0.026854) with: {'batch_size': 10, 'epochs': 50, 'model__init': 'normal', 'optimizer': 'adam'}\n",
      "0.688812 (0.020541) with: {'batch_size': 20, 'epochs': 50, 'model__init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.696630 (0.014228) with: {'batch_size': 20, 'epochs': 50, 'model__init': 'normal', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with grid search via sklearn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_shape=(8,), kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load Pima Indians dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# Split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# Create model wrapper\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "# Optional: print all available parameters\n",
    "print(model.get_params().keys())\n",
    "\n",
    "# Grid search setup\n",
    "optimizers = ['adam']\n",
    "init = ['glorot_uniform', 'normal']\n",
    "epochs = [50]\n",
    "batch_sizes = [10, 20]\n",
    "\n",
    "param_grid = dict(optimizer=optimizers,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_sizes,\n",
    "                  model__init=init)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn: 1.2.2\n",
      "scikeras: 0.11.0\n",
      "tensorflow: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import scikeras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"scikeras:\", scikeras.__version__)\n",
    "print(\"tensorflow:\", tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
