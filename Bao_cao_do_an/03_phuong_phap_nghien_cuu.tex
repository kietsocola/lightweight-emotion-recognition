\section{Phương pháp nghiên cứu} % section 3

\subsection{Thiết kế nghiên cứu} % section 3.1
Nghiên cứu được thiết kế theo phương pháp định lượng, tập trung vào việc xây dựng và đánh giá hiệu suất của các mô hình học sâu trong bài toán nhận diện biểu cảm khuôn mặt (Facial Expression Recognition - FER) trong điều kiện ánh sáng yếu. Phương pháp định lượng được chọn vì mục tiêu nghiên cứu là đo lường các chỉ số hiệu suất cụ thể (Accuracy, Precision, Recall, F1-score và thời gian suy luận) của hai mô hình CNN: MobileNetV3 (mô hình nhẹ) và ResNet18 (mô hình sâu hơn), khi áp dụng kỹ thuật tăng cường dữ liệu thích ứng.

Quá trình nghiên cứu bao gồm ba giai đoạn chính:
\begin{itemize}
    \item \textbf{Tiền xử lý dữ liệu:} Sử dụng tập dữ liệu FER-2013, áp dụng các kỹ thuật tăng cường dữ liệu thích ứng để mô phỏng điều kiện ánh sáng yếu.
    \item \textbf{Huấn luyện và tối ưu mô hình:} Triển khai MobileNetV3 và ResNet18, tinh chỉnh các tham số để phù hợp với bài toán FER.
    \item \textbf{Đánh giá và so sánh:} So sánh hiệu suất và thời gian suy luận của các mô hình khi có và không áp dụng kỹ thuật tăng cường dữ liệu thích ứng.
\end{itemize}

\subsection{Đối tượng và mẫu nghiên cứu} % section 3.2
\subsubsection{Đối tượng nghiên cứu}
Đối tượng nghiên cứu là các kỹ thuật nhận diện biểu cảm khuôn mặt trong điều kiện ánh sáng yếu, với trọng tâm vào:
\begin{itemize}
    \item \textbf{Mô hình học sâu:} MobileNetV3 và ResNet18 dùng để phân loại 7 biểu cảm khuôn mặt (vui, buồn, tức giận, sợ hãi, ngạc nhiên, ghê tởm, trung lập).
    \item \textbf{Kỹ thuật tăng cường dữ liệu thích ứng:} Các phương pháp như gamma correction, contrast stretching và histogram equalization, được điều chỉnh dựa trên đặc trưng ánh sáng của hình ảnh.
\end{itemize}

\subsubsection{Mẫu nghiên cứu}
Mẫu nghiên cứu là tập dữ liệu FER-2013, chứa 35.887 hình ảnh khuôn mặt (48x48 pixel, ảnh xám) được phân loại thành 7 biểu cảm. Tập dữ liệu được chia như sau:
\begin{itemize}
    \item Tập huấn luyện: 22.968 hình ảnh (~64\%).
    \item Tập xác thực (validation): 5.741 hình ảnh (~16\%).
    \item Tập kiểm tra: 7.178 hình ảnh (~20\%).
\end{itemize}


Nhằm mô phỏng điều kiện ánh sáng yếu, một tập dữ liệu phụ được tạo ra bằng cách giảm độ sáng của ảnh gốc. Quá trình này thực hiện bằng cách chuyển ảnh sang không gian màu HSV, giảm kênh độ sáng (V) theo một hệ số cố định, sau đó chuyển lại về không gian RGB. Cụ thể, độ sáng được giảm xuống 10\% so với ảnh ban đầu.

\subsection{Cách thu thập dữ liệu}
Dữ liệu được thu thập từ tập dữ liệu FER-2013 công khai trên nền tảng Kaggle. Các bước gồm:

\subsubsection*{Thu thập dữ liệu}
\begin{itemize}
    \item Tải tập dữ liệu FER-2013 từ Kaggle.
    \item Kiểm tra tính toàn vẹn (số lượng ảnh, định dạng, chất lượng).
\end{itemize}

\subsubsection*{Tiền xử lý dữ liệu}

Các bước tiền xử lý được thực hiện nhằm cải thiện chất lượng ảnh đầu vào và mô phỏng các điều kiện môi trường khác nhau, cụ thể như sau:

\begin{itemize}
    \item \textbf{Chuẩn hóa hình ảnh}: Loại bỏ nhiễu và đảm bảo định dạng đồng nhất (kích thước ảnh, không gian màu), giúp mô hình huấn luyện ổn định hơn.
    
    \item \textbf{Mô phỏng điều kiện ánh sáng yếu}: Để mô phỏng môi trường có ánh sáng yếu, hình ảnh được chuyển sang không gian màu HSV và kênh độ sáng (V) được giảm xuống còn 10\% so với ảnh gốc. Sau đó, ảnh được chuyển lại về không gian RGB để sử dụng trong huấn luyện.
\end{itemize}

\subsubsection*{Tăng cường dữ liệu thích ứng}
Áp dụng các phép biến đổi linh hoạt dựa trên đặc trưng ánh sáng của từng ảnh. Việc tăng cường được thực hiện bằng Python với OpenCV và NumPy.

\subsection{Phân tích dữ liệu}
\subsubsection{Công cụ và phần mềm}
\begin{itemize}
    \item Python: xử lý dữ liệu và huấn luyện mô hình.
    \item TensorFlow/Keras: xây dựng và đánh giá mô hình.
    \item OpenCV: tiền xử lý ảnh.
    \item NumPy, Pandas: quản lý dữ liệu.
    \item Matplotlib, Seaborn: trực quan hóa kết quả.
\end{itemize}

\subsubsection{Quy trình phân tích}
\begin{itemize}
    \item \textbf{Huấn luyện mô hình:}
    \begin{itemize}
        \item Sử dụng mô hình MobileNetV3Small với trọng số ImageNet, loại bỏ phần fully-connected gốc (include\_top=False).
        \item Chỉ tinh chỉnh 30 lớp cuối cùng trong mạng, các lớp còn lại được đóng băng để giữ lại đặc trưng đã học.
        \item Kiến trúc phần đầu ra gồm: Global Average Pooling, hai lớp Dense (128 và 64 nodes, activation ReLU), kèm Dropout 0.3, kết thúc bằng lớp Softmax với 7 nhãn đầu ra.
        \item Hàm mất mát: Categorical Crossentropy.
        \item Tối ưu hóa bằng Adam (learning rate mặc định).
        \item Số epoch: 10, sử dụng Early Stopping với patience = 3 để tránh overfitting.
    \end{itemize}

    \item \textbf{Đánh giá mô hình:}
    \begin{itemize}
        \item Các chỉ số đánh giá: Accuracy, Precision, Recall, F1-score.
        \item Đo thời gian suy luận trung bình trên CPU (per image).
        \item Kích cỡ mô hình sau huấn luyện.
    \end{itemize}

    \item \textbf{So sánh mô hình:}
    \begin{itemize}
        \item MobileNetV3 (cơ bản vs. tăng cường).
        \item ResNet18 (cơ bản vs. tăng cường).
        \item So sánh giữa MobileNetV3 và ResNet18.
    \end{itemize}
    
    \item \textbf{Phân tích kết quả:}
    \begin{itemize}
        \item Ma trận nhầm lẫn, biểu đồ Accuracy theo epoch.
        \item Quan sát các trường hợp dự đoán sai.
    \end{itemize}
\end{itemize}

\subsubsection{Thiết bị triển khai}
Thực nghiệm được thực hiện trên máy tính có CPU Intel Core i5, RAM 16GB. Sử dụng Google Colab để mô phỏng điều kiện tài nguyên thấp. Việc sử dụng CPU thay vì GPU giúp đánh giá thời gian suy luận gần với môi trường nhúng.

\subsection{Phương pháp so sánh}
Nghiên cứu tiến hành so sánh định lượng qua các chỉ số hiệu suất (Accuracy, Precision, Recall, F1-score) và thời gian suy luận giữa:
\begin{itemize}
    \item MobileNetV3 cơ bản vs. tăng cường.
    \item ResNet18 cơ bản vs. tăng cường.
    \item So sánh giữa MobileNetV3 và ResNet18.
\end{itemize}

Kết quả được trình bày dưới dạng bảng và biểu đồ để làm rõ hiệu quả của các kỹ thuật và sự phù hợp của mô hình trong ứng dụng thực tế.