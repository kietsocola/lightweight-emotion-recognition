\section{Thực nghiệm và thảo luận} % Section 4

\subsection{Thiết lập thực nghiệm} % Section 4.1

Trong phần này, chúng tôi tiến hành đánh giá hiệu suất của hai mô hình học sâu là \textbf{MobileNetV3Small} và \textbf{ResNet18} trong bài toán phân loại cảm xúc khuôn mặt trên tập dữ liệu FER2013. Mỗi mô hình được thử nghiệm trên ba biến thể của tập dữ liệu nhằm khảo sát khả năng thích nghi với điều kiện ánh sáng thay đổi và hiệu quả của các kỹ thuật tăng cường dữ liệu.

\begin{table}[H]
\centering
\caption{Kiến trúc mô hình MobileNetV3Small sử dụng trong thực nghiệm}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Layer (type)} & \textbf{Output Shape} & \textbf{Param \#} \\ \midrule
MobileNetV3Small (Functional)   & (None, 7, 7, 576) & 939,120 \\
GlobalAveragePooling2D          & (None, 576)       & 0       \\
Dense (128 units)               & (None, 128)       & 73,856  \\
Dropout                         & (None, 128)       & 0       \\
Dense (64 units)                & (None, 64)        & 8,256   \\
Dropout                         & (None, 64)        & 0       \\
Dense (7 units - output)        & (None, 7)         & 455     \\ \bottomrule
\end{tabular}
\label{tab:model-architecture}
\end{table}

Bảng~\ref{tab:model-architecture} mô tả kiến trúc của mô hình MobileNetV3Small được sử dụng trong thực nghiệm. Mô hình gốc MobileNetV3Small được sử dụng như một bộ trích xuất đặc trưng (feature extractor) đầu vào với đầu ra có kích thước \texttt{(7, 7, 576)}. Sau đó, lớp \texttt{GlobalAveragePooling2D} được áp dụng để giảm chiều không gian, tạo vector đặc trưng một chiều với 576 phần tử.

Tiếp theo là hai lớp \texttt{Dense} với số lượng đơn vị lần lượt là 128 và 64, đi kèm với các lớp \texttt{Dropout} nhằm giảm hiện tượng overfitting. Cuối cùng, lớp \texttt{Dense} đầu ra có 7 đơn vị tương ứng với 7 lớp cảm xúc cần phân loại.

Tổng số tham số huấn luyện của toàn bộ mô hình là khoảng 1 triệu, trong đó phần lớn nằm ở MobileNetV3Small. Việc sử dụng kiến trúc gọn nhẹ giúp mô hình đạt được hiệu quả cao mà vẫn đảm bảo tốc độ xử lý nhanh, phù hợp với các ứng dụng thực tế như trên thiết bị di động.
\begin{center}
\begin{longtable}{|l|c|c|}
\caption{Cấu trúc mô hình mạng học sâu} \\
\hline
\textbf{Layer (type)} & \textbf{Output Shape} & \textbf{Param \#} \\
\hline
\endfirsthead

\hline
\textbf{Layer (type)} & \textbf{Output Shape} & \textbf{Param \#} \\
\hline
\endhead

\hline \multicolumn{3}{r}{(tiếp trang sau)} \\
\endfoot

\hline
\textbf{Total Params} & & \textbf{11,180,103} \\
\textbf{Trainable Params} & & \textbf{11,180,103} \\
\textbf{Non-trainable Params} & & \textbf{0} \\
\hline
\endlastfoot

Conv2d-1 & [-1, 64, 112, 112] & 9,408 \\
BatchNorm2d-2 & [-1, 64, 112, 112] & 128 \\
ReLU-3 & [-1, 64, 112, 112] & 0 \\
MaxPool2d-4 & [-1, 64, 56, 56] & 0 \\
Conv2d-5 & [-1, 64, 56, 56] & 36,864 \\
BatchNorm2d-6 & [-1, 64, 56, 56] & 128 \\
ReLU-7 & [-1, 64, 56, 56] & 0 \\
Conv2d-8 & [-1, 64, 56, 56] & 36,864 \\
BatchNorm2d-9 & [-1, 64, 56, 56] & 128 \\
ReLU-10 & [-1, 64, 56, 56] & 0 \\
BasicBlock-11 & [-1, 64, 56, 56] & 0 \\
Conv2d-12 & [-1, 64, 56, 56] & 36,864 \\
BatchNorm2d-13 & [-1, 64, 56, 56] & 128 \\
ReLU-14 & [-1, 64, 56, 56] & 0 \\
Conv2d-15 & [-1, 64, 56, 56] & 36,864 \\
BatchNorm2d-16 & [-1, 64, 56, 56] & 128 \\
ReLU-17 & [-1, 64, 56, 56] & 0 \\
BasicBlock-18 & [-1, 64, 56, 56] & 0 \\
Conv2d-19 & [-1, 128, 28, 28] & 73,728 \\
BatchNorm2d-20 & [-1, 128, 28, 28] & 256 \\
ReLU-21 & [-1, 128, 28, 28] & 0 \\
Conv2d-22 & [-1, 128, 28, 28] & 147,456 \\
BatchNorm2d-23 & [-1, 128, 28, 28] & 256 \\
Conv2d-24 & [-1, 128, 28, 28] & 8,192 \\
BatchNorm2d-25 & [-1, 128, 28, 28] & 256 \\
ReLU-26 & [-1, 128, 28, 28] & 0 \\
BasicBlock-27 & [-1, 128, 28, 28] & 0 \\
Conv2d-28 & [-1, 128, 28, 28] & 147,456 \\
BatchNorm2d-29 & [-1, 128, 28, 28] & 256 \\
ReLU-30 & [-1, 128, 28, 28] & 0 \\
Conv2d-31 & [-1, 128, 28, 28] & 147,456 \\
BatchNorm2d-32 & [-1, 128, 28, 28] & 256 \\
ReLU-33 & [-1, 128, 28, 28] & 0 \\
BasicBlock-34 & [-1, 128, 28, 28] & 0 \\
Conv2d-35 & [-1, 256, 14, 14] & 294,912 \\
BatchNorm2d-36 & [-1, 256, 14, 14] & 512 \\
ReLU-37 & [-1, 256, 14, 14] & 0 \\
Conv2d-38 & [-1, 256, 14, 14] & 589,824 \\
BatchNorm2d-39 & [-1, 256, 14, 14] & 512 \\
Conv2d-40 & [-1, 256, 14, 14] & 32,768 \\
BatchNorm2d-41 & [-1, 256, 14, 14] & 512 \\
ReLU-42 & [-1, 256, 14, 14] & 0 \\
BasicBlock-43 & [-1, 256, 14, 14] & 0 \\
Conv2d-44 & [-1, 256, 14, 14] & 589,824 \\
BatchNorm2d-45 & [-1, 256, 14, 14] & 512 \\
ReLU-46 & [-1, 256, 14, 14] & 0 \\
Conv2d-47 & [-1, 256, 14, 14] & 589,824 \\
BatchNorm2d-48 & [-1, 256, 14, 14] & 512 \\
ReLU-49 & [-1, 256, 14, 14] & 0 \\
BasicBlock-50 & [-1, 256, 14, 14] & 0 \\
Conv2d-51 & [-1, 512, 7, 7] & 1,179,648 \\
BatchNorm2d-52 & [-1, 512, 7, 7] & 1,024 \\
ReLU-53 & [-1, 512, 7, 7] & 0 \\
Conv2d-54 & [-1, 512, 7, 7] & 2,359,296 \\
BatchNorm2d-55 & [-1, 512, 7, 7] & 1,024 \\
Conv2d-56 & [-1, 512, 7, 7] & 131,072 \\
BatchNorm2d-57 & [-1, 512, 7, 7] & 1,024 \\
ReLU-58 & [-1, 512, 7, 7] & 0 \\
BasicBlock-59 & [-1, 512, 7, 7] & 0 \\
Conv2d-60 & [-1, 512, 7, 7] & 2,359,296 \\
BatchNorm2d-61 & [-1, 512, 7, 7] & 1,024 \\
ReLU-62 & [-1, 512, 7, 7] & 0 \\
Conv2d-63 & [-1, 512, 7, 7] & 2,359,296 \\
BatchNorm2d-64 & [-1, 512, 7, 7] & 1,024 \\
ReLU-65 & [-1, 512, 7, 7] & 0 \\
BasicBlock-66 & [-1, 512, 7, 7] & 0 \\
AdaptiveAvgPool2d-67 & [-1, 512, 1, 1] & 0 \\
Linear-68 & [-1, 7] & 3,591 \\

\end{longtable}
\end{center}

Mô hình sử dụng là một biến thể của kiến trúc ResNet18 với tổng cộng \textbf{68 tầng}. Các tầng chính trong mô hình bao gồm:

\begin{itemize}
    \item \textbf{Conv2d}: Tầng tích chập, giúp trích xuất đặc trưng từ ảnh đầu vào.
    \item \textbf{BatchNorm2d}: Chuẩn hóa các giá trị đầu ra theo batch, giúp mô hình hội tụ nhanh hơn.
    \item \textbf{ReLU}: Hàm kích hoạt phi tuyến tính, tăng khả năng biểu diễn của mô hình.
    \item \textbf{MaxPool2d}: Gộp cực đại, giảm kích thước không gian và giữ lại đặc trưng quan trọng.
    \item \textbf{BasicBlock}: Khối residual trong ResNet giúp truyền gradient hiệu quả, giảm hiện tượng mất mát gradient trong mạng sâu.
    \item \textbf{AdaptiveAvgPool2d}: Lớp pooling trung bình thích ứng, đưa kích thước về dạng cố định để chuẩn bị cho tầng fully connected.
    \item \textbf{Linear}: Lớp kết nối đầy đủ (fully connected) để thực hiện phân loại đầu ra.
\end{itemize}

\vspace{0.5em}
\noindent \textbf{Lớp đầu ra (Output layer)} của mô hình là \texttt{Linear-68} với \textbf{7 đơn vị đầu ra}, tương ứng với \textbf{7 lớp cảm xúc} trong bài toán phân loại (ví dụ: \textit{Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise}).

\vspace{0.5em}
\noindent \textbf{Khối BasicBlock}: ResNet18 sử dụng các khối residual (\textit{BasicBlock}) để khắc phục hiện tượng suy giảm gradient trong các mạng học sâu. Trong mô hình này, mỗi giai đoạn chứa 2 \texttt{BasicBlock}, ngoại trừ giai đoạn đầu tiên. Tổng cộng mô hình sử dụng \textbf{16 khối BasicBlock}, phù hợp với kiến trúc gốc của ResNet18.

Tổng số tham số huấn luyện của toàn bộ mô hình là khoảng 11,180,103 tham số

\subsection{Biểu đồ, bảng biểu, hình ảnh minh hoạ} % Section 4.2

\subsubsection{MobileNetV3Small}

\begin{table}[H]
\centering
\caption{Độ chính xác của các phiên bản mô hình MobileNetV3Small trên tập dữ liệu FER2013}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Tên kiến trúc} & \textbf{Độ chính xác (\%)} \\ \midrule
MobileNetV3Small + FER2013 & 61.63 \\
MobileNetV3Small + FER2013 (Low Light Images - LLI) & 58.86 \\
MobileNetV3Small + FER2013 (LLI + adaptive augmentation) & 61.55 \\ \bottomrule
\end{tabular}
\label{tab:training-results}
\end{table}

Bảng~\ref{tab:training-results} trình bày độ chính xác khi huấn luyện mô hình MobileNetV3Small trên các phiên bản khác nhau của tập dữ liệu FER2013. Trong đó, FER2013 là tập dữ liệu gốc chứa các hình ảnh khuôn mặt thể hiện cảm xúc. 

Khi huấn luyện trên tập FER2013 gốc, mô hình đạt độ chính xác cao nhất là 61.63\%. Việc mô phỏng điều kiện ánh sáng yếu thông qua tập dữ liệu LLI làm giảm độ chính xác mô hình, phản ánh thách thức trong việc nhận diện cảm xúc dưới điều kiện chiếu sáng kém, giảm còn 58.86\%. Tuy nhiên, khi kết hợp LLI với phương pháp tăng cường dữ liệu thích ứng (adaptive augmentation), độ chính xác cải thiện đáng kể lên 61.55\%, gần tương đương với mô hình gốc. 

Điều này cho thấy rằng các kỹ thuật tăng cường dữ liệu phù hợp có thể giúp mô hình thích nghi tốt hơn với điều kiện ánh sáng kém, nhưng cần được áp dụng và điều chỉnh một cách hợp lý để tránh làm nhiễu thông tin đầu vào.


\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{img/confusionMatrixMobilenetV3.png}
\caption{Ma trận nhầm lẫn trên tập kiểm tra của mô hình MobileNetV3}
\label{fig:confusion-mobilenetv3}
\end{figure}

Hình~\ref{fig:confusion-mobilenetv3} trình bày ma trận nhầm lẫn của mô hình \textbf{MobileNetV3} trong nhiệm vụ phân loại cảm xúc khuôn mặt. Kết quả cho thấy mô hình nhận diện tốt các cảm xúc có đặc trưng rõ ràng như:

\begin{itemize}
    \item \textbf{Happy}: có \textbf{1,491} mẫu được dự đoán đúng (\textbf{95.40\%}).
    \item \textbf{Neutral}: có \textbf{939} mẫu đúng (\textbf{64.22\%}).
    \item \textbf{Surprise}: đạt \textbf{601} mẫu đúng (\textbf{86.48\%}).
\end{itemize}

Tuy nhiên, hiệu suất giảm đáng kể với các cảm xúc khó phân biệt hơn:

\begin{itemize}
    \item \textbf{Disgust}: chỉ \textbf{11} mẫu được nhận diện đúng (\textbf{21.57\%}), trong khi bị nhầm sang \textbf{Angry} tới \textbf{28} mẫu (\textbf{54.90\%}).
    
    \item \textbf{Fear}: chỉ \textbf{42} mẫu đúng (\textbf{8.57\%}), trong khi bị nhầm với:
    \begin{itemize}
        \item \textbf{Neutral}: \textbf{224} mẫu (\textbf{45.71\%})
        \item \textbf{Sad}: \textbf{179} mẫu (\textbf{36.53\%})
        \item \textbf{Angry}: \textbf{145} mẫu (\textbf{29.59\%})
    \end{itemize}

    \item \textbf{Sad}: chỉ \textbf{107} mẫu đúng (\textbf{17.63\%}), bị nhầm với:
    \begin{itemize}
        \item \textbf{Neutral}: \textbf{395} mẫu (\textbf{65.07\%})
        \item \textbf{Fear}: \textbf{91} mẫu (\textbf{14.98\%})
    \end{itemize}
\end{itemize}

Tổng thể, ma trận nhầm lẫn cung cấp cái nhìn rõ nét về khả năng mô hình phân biệt giữa các cảm xúc. Trong khi các cảm xúc tích cực như \textit{happy} và \textit{surprise} đạt hiệu suất cao, các cảm xúc tiêu cực như \textit{fear}, \textit{sad} và \textit{disgust} dễ bị nhầm lẫn lẫn nhau, đòi hỏi cải tiến thêm về dữ liệu huấn luyện và biểu diễn đặc trưng.

\subsubsection{ResNet18}

\begin{table}[H]
\centering
\caption{Độ chính xác của các phiên bản mô hình ResNet18 trên tập dữ liệu FER2013}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Tên kiến trúc} & \textbf{Độ chính xác (\%)} \\ \midrule
ResNet18 + FER2013 & 67.23 \\
ResNet18 + FER2013 (Low Light Images - LLI) & 67.04 \\
ResNet18 + FER2013 (LLI + adaptive augmentation) & 67.48 \\ \bottomrule
\end{tabular}
\label{tab:resnet-results}
\end{table}


Bảng~\ref{tab:resnet-results} thể hiện độ chính xác của mô hình ResNet18 khi huấn luyện trên các phiên bản khác nhau của tập dữ liệu FER2013. Tương tự như mô hình MobileNetV3Small, FER2013 là tập dữ liệu ảnh khuôn mặt thể hiện cảm xúc.

Mô hình ResNet18 huấn luyện trên tập FER2013 gốc đạt độ chính xác cao nhất là 67.23\%. Khi sử dụng phiên bản ảnh ánh sáng yếu (Low Light Images - LLI), độ chính xác chỉ giảm nhẹ còn 67.04\%. Đáng chú ý, việc kết hợp thêm phương pháp tăng cường dữ liệu thích ứng (adaptive augmentation) giúp cải thiện hiệu suất lên mức 67.48\%, vượt cả mô hình gốc.

Kết quả này cho thấy ResNet18 có khả năng học tốt trong điều kiện ánh sáng kém và có thể tận dụng tốt lợi ích từ các kỹ thuật tăng cường dữ liệu phù hợp.



\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{img/confusionMatrixResnet18.png}
\caption{Ma trận nhầm lẫn phần trăm trên tập kiểm tra của mô hình ResNet18}
\label{fig:confusion-resnet18}
\end{figure}

Phân tích ma trận nhầm lẫn thể hiện tại Hình~\ref{fig:confusion-resnet18} cho thấy hiệu quả phân loại cảm xúc của mô hình ResNet18 trên tập kiểm tra. Mô hình đạt độ chính xác cao đối với các cảm xúc như \textit{Happy} (85.25\%) và \textit{Surprise} (78.80\%), tương đồng với các nghiên cứu trước đó về độ dễ nhận diện của các cảm xúc này qua biểu cảm khuôn mặt.

Ngược lại, các cảm xúc như \textit{Fear}, \textit{Sad} và \textit{Disgust} có xu hướng bị nhầm lẫn nhiều, đặc biệt là giữa các cặp có biểu hiện tương tự về hình thái học (ví dụ: \textit{Fear} và \textit{Sad}). Điều này cho thấy mô hình vẫn còn hạn chế trong việc tách biệt các đặc trưng tinh vi giữa các cảm xúc gần nhau về biểu cảm, một thách thức phổ biến trong nhận diện cảm xúc.

Những kết quả này gợi ý rằng việc cải thiện mô hình có thể tập trung vào việc xử lý mất cân bằng lớp, sử dụng dữ liệu tăng cường phù hợp và áp dụng kỹ thuật học sâu nâng cao để tăng cường khả năng phân biệt giữa các cảm xúc dễ gây nhầm lẫn.


\subsection{Đánh giá, giải thích kết quả nghiên cứu}

\begin{table}[H]
\centering
\caption{Kết quả tổng thể của các mô hình}
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{5cm}cccc@{}}
\toprule
\textbf{Tên kiến trúc} & \textbf{Accuracy (\%)} & \textbf{F1-score (\%)} & \textbf{Time infer (ms)} & \textbf{Size (MB)} \\ \midrule
MobileNetV3Small & 61.63 & 60 & 2.15 & 13.54 \\
ResNet18 & 67.23 & 67 & 3.44 & 42.73 \\
MobileNetV3Small + FER2013 LLI & 58.86 & 58 & 2.10 & 13.54 \\
ResNet18 + FER2013 LLI & 67.04 & 67 & 3.18 & 42.72 \\
MobileNetV3Small + FER2013 LLI + adaptive augmentation & 61.55 & 60 & 2.12 & 13.54 \\
ResNet18 + FER2013 LLI + adaptive augmentation & 67.48 & 67 & 2.91 & 42.72 \\ \bottomrule
\end{tabular}
\label{tab:overall-results}
\end{table}

Bảng trên tổng hợp các chỉ số chính của các mô hình thử nghiệm, bao gồm độ chính xác (Accuracy), F1-score, thời gian suy luận trên mỗi mẫu (Time inference), và kích thước mô hình (Size). 

\textbf{Nhận xét:}

\begin{itemize}
    \item \textbf{Hiệu suất nhận diện:} Mô hình ResNet18 cho kết quả vượt trội hơn hẳn MobileNetV3Small về độ chính xác và F1-score, chứng tỏ khả năng biểu diễn đặc trưng sâu sắc và hiệu quả hơn cho bài toán phân loại cảm xúc.
    
    \item \textbf{Ảnh hưởng của dữ liệu ánh sáng yếu (LLI):} Cả hai mô hình đều giảm nhẹ độ chính xác khi huấn luyện trên tập dữ liệu LLI, tuy nhiên sự sụt giảm này không đáng kể, đặc biệt là với ResNet18. Điều này cho thấy các kiến trúc mạng này có độ bền tốt với các biến đổi về điều kiện ánh sáng.
    
    \item \textbf{Tác động của kỹ thuật tăng cường dữ liệu thích ứng:} Khi kết hợp LLI với adaptive augmentation, độ chính xác của cả hai mô hình đều được cải thiện và gần đạt bằng hoặc vượt mức mô hình gốc. Đặc biệt với ResNet18, mức cải thiện rõ ràng và thời gian suy luận cũng giảm nhẹ, chứng tỏ kỹ thuật tăng cường dữ liệu giúp mô hình học được đặc trưng phong phú hơn và tăng khả năng tổng quát hóa.
    
    \item \textbf{Hiệu năng và kích thước mô hình:} MobileNetV3Small có lợi thế vượt trội về kích thước nhỏ gọn và thời gian suy luận nhanh hơn, phù hợp cho các ứng dụng thực tế trên thiết bị di động hoặc các hệ thống giới hạn tài nguyên. Ngược lại, ResNet18 với hiệu suất cao hơn đi kèm kích thước và thời gian suy luận lớn hơn, thích hợp cho các hệ thống yêu cầu độ chính xác cao.
\end{itemize}

\textbf{Kết luận:} 

Việc lựa chọn mô hình phụ thuộc vào mục tiêu ứng dụng cụ thể. Nếu ưu tiên độ chính xác và khả năng xử lý đa dạng điều kiện ánh sáng, ResNet18 là lựa chọn tối ưu. Trong khi đó, MobileNetV3Small phù hợp cho các ứng dụng cần tối ưu tài nguyên và tốc độ xử lý. Bên cạnh đó, áp dụng kỹ thuật tăng cường dữ liệu thích ứng được khuyến khích để cải thiện độ bền mô hình trong các môi trường ánh sáng thay đổi, giúp tăng khả năng nhận diện cảm xúc chính xác và ổn định hơn.

\subsection{So sánh với các nghiên cứu trước}
Để đánh giá tính hiệu quả và tính mới của phương pháp đề xuất, chúng tôi so sánh pipeline sử dụng MobileNetV3-Small kết hợp kỹ thuật tăng cường dữ liệu thích ứng với các phương pháp nhận diện biểu cảm khuôn mặt (FER) trong điều kiện ánh sáng yếu được đề cập trong các nghiên cứu trước. Bảng~\ref{tab:compare_sota} tổng hợp các chỉ số hiệu suất, thời gian suy luận, và yêu cầu tài nguyên của phương pháp đề xuất so với các phương pháp tiêu biểu.

\begin{table}[H]
\centering
\caption{So sánh phương pháp đề xuất với các nghiên cứu trước}
\label{tab:compare_sota}
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{5cm}cccc@{}}
\toprule
\textbf{Phương pháp} & \textbf{Accuracy (\%)} & \textbf{F1-score (\%)} & \textbf{Thời gian (ms)} & \textbf{Kích thước (MB)} \\ \midrule
VGGNet~\cite{goodfellow2014} & 70.5 & 69.0 & 10.2 & 500+ \\
InceptionNet~\cite{goodfellow2014} & 72.3 & 71.0 & 8.5 & 200+ \\
EnlightenGAN~\cite{zhang2021} & 68.0 & 66.5 & 15.0 & 1000+ \\
RetinexNet~\cite{wang2022} & 65.5 & 64.0 & 12.0 & 800+ \\
ResNet18 + FER2013 LLI + adaptive augmentation (chúng tôi thực nghiệm) & 67.48 & 67.0 & 2.91 & 42.72 \\
\textbf{MobileNetV3-Small + FER2013 LLI + adaptive augmentation (đề xuất)} & 61.55 & 60.0 & 2.12 & 13.54 \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Nhận xét:}
\begin{itemize}
    \item \textbf{Hiệu suất nhận diện}: Các mô hình nặng như VGGNet và InceptionNet đạt độ chính xác cao hơn (70.5--72.3\%) trên tập FER-2013 trong điều kiện ánh sáng bình thường~\cite{goodfellow2014}. Tuy nhiên, trong điều kiện ánh sáng yếu (LLI), hiệu suất của các mô hình này thường giảm đáng kể (ước tính giảm 10--20\%) do thiếu tiền xử lý thích ứng~\cite{mollahosseini2016}. Phương pháp đề xuất đạt độ chính xác 61.55\% trong điều kiện ánh sáng yếu, thấp hơn VGGNet và InceptionNet nhưng cải thiện 2.7\% so với MobileNetV3-Small không tăng cường (58.86\%) và gần tương đương với hiệu suất trên tập gốc (61.63\%).
    \item \textbf{Phương pháp dựa trên GAN}: EnlightenGAN~\cite{zhang2019b} và RetinexNet~\cite{wang2022} cải thiện chất lượng ảnh ánh sáng yếu nhưng đạt độ chính xác thấp hơn (65.5--68.0\%) và yêu cầu tài nguyên tính toán lớn (kích thước mô hình 800--1000 MB, thời gian suy luận 12--15 ms). Phương pháp đề xuất sử dụng các kỹ thuật đơn giản (gamma correction, CLAHE) đạt hiệu suất tương đối cạnh tranh (61.55\%) với tài nguyên thấp hơn đáng kể (13.54 MB, 2.12 ms).
    \item \textbf{Thời gian suy luận và kích thước mô hình}: So với ResNet18 (2.91 ms, 42.72 MB), MobileNetV3-Small có thời gian suy luận nhanh hơn (2.12 ms) và kích thước nhỏ hơn (13.54 MB), phù hợp hơn cho các thiết bị nhúng. Các mô hình như VGGNet và InceptionNet có thời gian suy luận dài (8.5--10.2 ms) và kích thước lớn (200--500 MB), không khả thi cho ứng dụng thực tế trên thiết bị hạn chế tài nguyên.
    \item \textbf{Khả năng triển khai thực tế}: Pipeline tăng cường dữ liệu thích ứng của phương pháp đề xuất tự động điều chỉnh các kỹ thuật tiền xử lý (gamma correction, CLAHE, contrast stretching) dựa trên đặc trưng ánh sáng, giúp cải thiện độ bền trong môi trường ánh sáng yếu mà không cần phần cứng cao cấp. Ngược lại, các phương pháp như EnlightenGAN và RetinexNet yêu cầu GPU mạnh, hạn chế khả năng triển khai trên camera giám sát hoặc thiết bị IoT.
\end{itemize}

\textbf{Kết luận}: Phương pháp đề xuất không đạt độ chính xác cao nhất so với các mô hình nặng như VGGNet hay InceptionNet trong điều kiện ánh sáng bình thường. Tuy nhiên, trong điều kiện ánh sáng yếu, phương pháp này cung cấp sự cân bằng tối ưu giữa hiệu suất (61.55\%), tốc độ suy luận (2.12 ms), và kích thước mô hình (13.54 MB), vượt trội so với các phương pháp dựa trên GAN về tính khả thi triển khai. So với ResNet18, phương pháp đề xuất phù hợp hơn cho các ứng dụng yêu cầu tài nguyên thấp, chẳng hạn như camera giám sát hoặc thiết bị IoT. Những kết quả này khẳng định tính mới của pipeline tăng cường dữ liệu thích ứng trong việc cải thiện độ bền của mô hình FER trong điều kiện ánh sáng yếu.

\subsection{Nêu ý nghĩa thực tiễn của nghiên cứu}
\begin{itemize}
    \item Cải thiện độ chính xác trong điều kiện ánh sáng yếu: Hệ thống nhận diện cảm xúc thường gặp khó khăn khi môi trường thiếu sáng (ví dụ: buổi tối, trong xe hơi, phòng họp mờ...). Nghiên cứu này giúp khắc phục vấn đề đó, tăng độ tin cậy và ổn định của mô hình trong điều kiện thực tế.
    \item Giảm chi phí phần cứng: Thay vì cần máy ảnh chất lượng cao để chụp rõ trong điều kiện ánh sáng kém, việc tăng cường ảnh bằng phần mềm cho phép sử dụng thiết bị giá rẻ, phù hợp với triển khai diện rộng.
\end{itemize}

\subsection{Những hạn chế , đề xuất nghiên cứu tiếp theo}

\subsubsection{Hạn chế}
\begin{itemize}
    \item Độ chỉnh xác tổng thể còn thấp
    \item Còn nhầm lẫn giữa Disgust và Fear , Fear và Sad
    \item Đôi khi việc áp dụng kĩ thuật tăng cường có thể làm cho thời gian suy luận ảnh lâu hơn
\end{itemize}

\subsubsection{Đề xuất nghiên cứu}
\begin{itemize}
    \item Ứng dụng các mô hình học sâu để tăng cường ảnh : Thử nghiệm các phương pháp tăng cường ảnh hiện đại như Deep Image Enhancement, GANs cho ảnh ánh sáng yếu để cải thiện chất lượng đầu vào.
    \item Thu thập và mở rộng tập dữ liệu ánh sáng yếu : Xây dựng bộ dữ liệu đa dạng hơn về độ tuổi, giới tính, điều kiện ánh sáng, biểu cảm phức tạp hơn để huấn luyện và kiểm thử mô hình.
    \item Phát triển mô hình nhẹ, tối ưu thời gian suy luận : Áp dụng kỹ thuật như quantization, pruning, hoặc thiết kế lại kiến trúc nhẹ (MobileNet, EfficientNet) để giảm độ trễ khi triển khai thực tế.
\end{itemize}

